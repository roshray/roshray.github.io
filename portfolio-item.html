<!DOCTYPE html>
<html lang="en">
    <head><link rel="stylesheet" href="normalize.css">
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Roshan Ray Portfolio Website</title>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/7.0.0/normalize.min.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.css" integrity="sha256-46qynGAkLSFpVbEBog43gvNhfrOj+BmwXdxFgVK/Kvc=" crossorigin="anonymous" />  
        
        <!-- Update these with your own fonts -->
        <link href="https://fonts.googleapis.com/css?family=Lora:400,700|Roboto+Slab:400,700&display=swap" rel="stylesheet"> 
        
        <link rel="stylesheet" href="css/style.css">

    </head>
    <body>
        <header>
            <div class="logo">
                <img src="img/rosh.jpg" alt="">
            </div>
            <button class="nav-toggle" aria-label="toggle navigation">
                <span class="hamburger"></span>
            </button>
            <nav class="nav">
                <ul class="nav__list">
                    <li class="nav__item"><a href="index.html" class="nav__link">Home</a></li>
                    <li class="nav__item"><a href="index.html#services" class="nav__link">My Services</a></li>
                    <li class="nav__item"><a href="index.html#about" class="nav__link">About me</a></li>
                    <li class="nav__item"><a href="index.html#work" class="nav__link">My Work</a></li>
                </ul>
            </nav>
        </header>
        

        <section class="intro">
            <h1 class="section__title section__title--intro">
                Human-level control through  <strong>deep reinforcement learning</strong>
            </h1>
            <p class="section__subtitle section__subtitle--intro">A Central goal of general artificial intelligence</p>
            <img src="img/DQN_ER.png" alt="" class="intro__img">
        </section>
        
        <div class="portfolio-item-individual">
            <p> The deep Q-network agent,receiving 
                only the pixels and the game score as inputs,was able to surpass the performance of all previous 
                algorithms and achieve a level comparable to that of a pro-fessional human games </p>
            <img src="img/Atari.png" alt="">
           
            <p> 
            
            
            Train the network to minimize the TD error R + delta * max_a Q(s_(t+1), a) - Q(s_t, a).
            During optimization, keep the parameters off the Q(s_(t+1), a) term fixed.
                You make a copy of the Q network and call this the target network.
            Practical points that make it work
                
            Experience replay
                
            Avoid correlation of samples used to train the network by creating a buffer of experience. 
                When training the Q network, take a mini batch from the buffer and use it for training. 
                When playing the game, keep adding tuples of reward, action, state, state at next step. 
                The buffer will contain these tuples and can have a maximal capacity
                (you can prioritize what you get out of the buffer and 
                how you replace the elements in the buffer when the buffer is full).
                
            Frame stacking
                
            To create the states of the RL problem, stack 4 consecutive screens of the game. This fixes some pixel problems with Atari and shows the model how the frames are changing according to actions.
            Target network update
            Since the target network is fixed during optimization, one can decide to update the target network every C updates of the Q network. This minimizes oscilations in updates and the chance of divergence.
            Error function change
            The error term from the TD update is clipped to be between -1 and 1. This effectively makes the loss function to be the absolute value of the difference for values that are not in between -1 and 1.</p>
                    </div>
        
        
        <!-- Footer -->
        <footer class="footer">
            <!-- replace with your own email address -->
            <a href="mailto:roshanroy759@gmail.com" class="footer__link">roshanroy759@gmail.com</a>
            <ul class="social-list">
                <li class="social-list__item">
                    <a class="social-list__link" href="https://in.linkedin.com/in/roshan-ray-85765ba2">
                        <i class="fab fa-linkedin"></i>
                    </a>
                </li>
                <li class="social-list__item">
                    <a class="social-list__link" href="https://github.com/roshray/roshray.github.io/blob/master/Co-resume.docx%20-%20Google%20Docs.pdf">
                        <i class="Resume"></i>
                    </a>
                </li>
                <li class="social-list__item">
                    <a class="social-list__link" href="https://twitter.com">
                        <i class="fab fa-twitter"></i>
                    </a>
                </li>
                <li class="social-list__item">
                    <a class="social-list__link" href="https://github.com/roshray">
                        <i class="fab fa-github"></i>
                    </a>
                </li>
            </ul>
        </footer>
        
        
        <script src="js/index.js"></script>
        
    </body>
</html>
